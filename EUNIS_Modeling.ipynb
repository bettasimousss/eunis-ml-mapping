{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c924e845",
   "metadata": {},
   "source": [
    "# EUNIS Habitat Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b6c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98462774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ff0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0874b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "graine = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52872448",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['MA2','N','P','Q','R','S','T','U','V']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ef21d",
   "metadata": {},
   "source": [
    "### Habitats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db49edb-f099-4003-a863-6f694d655bc2",
   "metadata": {},
   "source": [
    "CLEANING RULES:\n",
    "- Specific to each habitat, done prior to the modelling\n",
    "- Involves the following criteria, to adapt according to the habitat of interest:\n",
    "    - Min date of observation\n",
    "    - Location uncertainty: set according to habitat minimum extent\n",
    "    - Landcover match in the surroundings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143cb7e7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "eva_data = pd.read_csv('dataset/EVA_EUNIS.csv',low_memory=False,index_col=0)[['PlotObservationID','source','year','LocationUncertainty','Longitude','Latitude','X','Y','EUNIS','EUNIS1','EUNIS2','EUNIS3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae2e8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "au_data = pd.read_csv('dataset/AUSTRIA_EUNIS.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f072ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_data_long = au_data.melt(id_vars=['grid','X','Y','CLC'],var_name='EUNIS',value_name='occ').query('occ>0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b03c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_data_long['EUNIS']=au_data_long['EUNIS'].replace(['MAa','MA'],'MA2')\n",
    "au_data_long['EUNIS1']=au_data_long['EUNIS'].apply(lambda x: 'MA2' if 'MA' in x else x[0:1] if x[0:1] in targets else '')\n",
    "au_data_long['EUNIS2']=au_data_long['EUNIS'].apply(lambda x: '' if len(x)<2 else x[0:2] if 'MA' not in x else '' if len(x)<=3 else x[0:4])\n",
    "au_data_long['EUNIS3']=au_data_long['EUNIS'].apply(lambda x: '' if len(x)<3 else x[0:3] if 'MA' not in x else '' if len(x)<=4 else x[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99910b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pt_data = pd.read_csv('dataset/PORTUGAL_EUNIS.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d7518-3cdd-41ca-b6ef-cf77116cf1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifn_data = pd.read_csv('dataset/IFN_EUNIS.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a7e78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlpt_data = pd.read_csv('dataset/NLPT_EUNIS.csv',index_col=0)\n",
    "nlpt_data['EUNIS']=nlpt_data['EUNIS'].replace(['MAa','MA'],'MA2')\n",
    "nlpt_data['EUNIS1']=nlpt_data['EUNIS'].apply(lambda x: 'MA2' if 'MA' in x else x[0:1] if x[0:1] in targets else '')\n",
    "nlpt_data['EUNIS2']=nlpt_data['EUNIS'].apply(lambda x: '' if len(x)<2 else x[0:2] if 'MA' not in x else '' if len(x)<=3 else x[0:4])\n",
    "nlpt_data['EUNIS3']=nlpt_data['EUNIS'].apply(lambda x: '' if len(x)<3 else x[0:3] if 'MA' not in x else '' if len(x)<=4 else x[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dcf67f",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b07fa5",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42294811",
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_env = pd.read_csv('dataset/EVA_env_full.csv',index_col=0).dropna(subset=['PlotObservationID','Longitude','Latitude'],axis=0)\n",
    "eva_env['PlotObservationID']=eva_env['PlotObservationID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_env = eva_env.groupby(['PlotObservationID','Longitude','Latitude','X','Y']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e408dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_dataset = pd.merge(eva_data,calib_env,on=['PlotObservationID','Longitude','Latitude','X','Y']).drop_duplicates()\n",
    "calib_dataset = calib_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15519365-68ba-4dcf-91b7-612a078385dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d31dfcc2",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5346882",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpt_env = pd.read_csv('dataset/NLPT_env_full.csv',index_col=0)\n",
    "nlpt_dataset = pd.merge(nlpt_env, nlpt_data)\n",
    "nlpt_dataset.columns = ['grid']+nlpt_dataset.columns.tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4804ac-b62a-4ba1-9205-329d6881975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifn_env = pd.read_csv('dataset/IFN_env_full.csv',index_col=0)\n",
    "ifn_dataset = pd.merge(ifn_env, ifn_data)\n",
    "ifn_dataset.columns = ['grid']+ifn_dataset.columns.tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_env = pd.read_csv('dataset/PORTUGAL_env_full.csv',index_col=0)\n",
    "pt_dataset = pd.concat([pt_env.loc[pt_data['grid'],:],pt_data.set_index('grid').drop(['CLC','X','Y'],axis=1)],axis=1)\n",
    "pt_dataset['grid']=pt_dataset.index\n",
    "pt_dataset.columns=pt_dataset.columns.tolist()[:-5]+['EUNIS','EUNIS1','EUNIS2','EUNIS3','grid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d2ade8-77da-4ede-ab88-5ccbc333719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_env = pd.read_csv('dataset/AUSTRIA_env_full.csv',index_col=0)\n",
    "au_dataset = pd.concat([au_env.loc[au_data_long['grid'].tolist(),:],au_data_long.set_index('grid').drop(['CLC','X','Y'],axis=1)],axis=1)\n",
    "au_dataset['grid']=au_dataset.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f162717-f8bb-4d2c-9c9c-dfdf46391581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f58f96-98c1-425a-b6ec-69f54727a1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6ef9b9f",
   "metadata": {},
   "source": [
    "## Cross-validation settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dbb92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f19ce8-097b-4c6d-8c7a-e41d06041cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_data['eea_100km'] = calib_data[['X','Y']].apply(lambda arr: set_eea_geom(arr[0],arr[1]),axis=1)\n",
    "calib_data['grid']=calib_data.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b07f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_split = False\n",
    "if do_split:\n",
    "    for cl in targets:\n",
    "        print('Generating cross-validation splits for %s'%cl)\n",
    "        cl_data, cl_split = mlsplit(calib_data,cl,n_splits,level=3 if cl!='P' else 2)\n",
    "        joblib.dump([cl_data, cl_split],'partitions/%s.joblib'%cl)\n",
    "        plot_partition(cl_data,level=3 if cl!='P' else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f37302",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_split:\n",
    "    for cl in targets:\n",
    "        cl_data, cl_split = joblib.load('partitions/%s.joblib'%cl)\n",
    "        plot_partition(cl_data,level=3 if cl!='P' else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedee24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b370d114",
   "metadata": {},
   "source": [
    "## Modelling utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6503843a-72ec-44da-8f88-d6fd9fe60ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b263395-353f-417d-9de3-d73884912b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.models.evaluation import *\n",
    "from source.models.preprocessing import *\n",
    "from source.models.calibration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad15c731-75cd-46db-aa22-3bfe1598df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.models.baselines import *\n",
    "from source.habitat_model import *\n",
    "from source.models.neural_habitat_model import *\n",
    "from source.models.tabnet_habitat_model import *\n",
    "from source.models.decision_forest_habitat_models import *\n",
    "from source.models.gam_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968cbde6-69c3-40b7-b76b-e46300ff3970",
   "metadata": {},
   "source": [
    "### Data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55acb530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_metadata = pd.read_csv('config/feature_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea4e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eunis_vars = ['EUNIS1','EUNIS2','EUNIS3']\n",
    "geo_vars = ['X','Y','Longitude','Latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d45ff5-a389-4cc6-a2f1-42aa9754b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abio_vars = ['bio01', 'bio04', 'gdd5', 'bio12', 'bio15', 'scd','swe', ###climate variables available in the future\n",
    "            'distace2FW', 'distance2Coast','inundation_seasonality', ### hydrography\n",
    "            'TPILF','TRI','aspect',### Topography\n",
    "            'dr','parmado',   ### Geology\n",
    "            'AWC','BulkDensity', 'CoarseFragments', 'SandE', 'SiltE', 'ClayE',  ### Physical soil structure\n",
    "            'pH_H2O', 'C', 'N', 'CEC', 'CaCO3']  ### Chemical properties of the soil\n",
    "\n",
    "rs_vars =  ['canopy_height', 'lai_spring', 'lai_summer', 'canopy_density', ## structure\n",
    "            'SOSD', 'LSLOPE', 'AMPL', 'RSLOPE', 'LENGTH', 'TPROD',  ### phenology\n",
    "            #'perma_water', 'perma_wet', 'temp_water', 'temp_wet', ### hydrography\n",
    "            'Grassland', 'Tree_cover', 'Built_up', 'Bare_sparse_vegetation', 'Cropland', \n",
    "            'Permanent_water_bodies', 'Herbaceous_wetland', 'Shrubland', 'Moss_lichen', 'Snow_ice'\n",
    "           ]         \n",
    "\n",
    "tpilf_categs = ['foot slopes','high ridges','local ridges','mid-slope drainages','mid-slope ridges',\n",
    "                'plains','streams','upland drainage','upper slopes','valleys']\n",
    "\n",
    "parmado_categs = ['No information','clastic-sedimentary','sedimentary','calcareous','limestone','dolomite','marl',\n",
    "  'chalk','evaporites','siliceous','igneous','plutonic','volcanic','pyroclastic','metamorphic','marine_deposits',\n",
    "  'fluvial_deposits','lake_deposits','residual_loam_deposits','residual_clay_deposits','slope_deposits','glacial_deposits',\n",
    "  'eolian_deposits','organic_material','peat','slime_ooze','anthropo_deposits']\n",
    "\n",
    "categories = [tpilf_categs,parmado_categs]\n",
    "cat_vars = ['TPILF','parmado']\n",
    "\n",
    "pred_vars = abio_vars + rs_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e38592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ce770d0",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe03937-ef73-4c37-ac62-5533e2848715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_config(algo_name,config_file):\n",
    "    with open(config_file) as fp:\n",
    "        param_dict = json.load(fp)\n",
    "        param_dict.update({\n",
    "            'inputs':{\n",
    "                'metadata': feature_metadata,\n",
    "                'categories': categories,\n",
    "                'std': True if algo_name in [\"gam\",\"mlp\",\"tabnet\"] else False\n",
    "                'onehot': 0 if algo_name in [\"xgb\",\"catboost\"] else 1 if algo_name in [\"rf\",\"gam\",\"mlp\"] else 2 if algo_name in [\"lgbm\",\"tabnet\"] else None\n",
    "                'groups': None\n",
    "            }\n",
    "        })\n",
    "\n",
    "    return param_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec68be7-4aff-4be6-b50c-7c931551f4ff",
   "metadata": {},
   "source": [
    "#### Train the ensemble habitat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_ensemble(cl,cl_dataset,eva_vars,model_tuples,out_folder):\n",
    "    cl_att = 'EUNIS3' if cl!='P' else 'EUNIS2'\n",
    "    target_data = cl_dataset.query('%s==%s'%(cl_att,cl_att)).dropna(subset=eva_vars+[cl_att,'fold','dataset'])\n",
    "    \n",
    "    for mod, algo in model_tuples:\n",
    "        params = load_config(algo,'config/%s_config/%s.json'%(cl,mod))\n",
    "        out_dir = '%s/%s/%s/'%(out_folder,cl,algo)\n",
    "        os.makedirs(out_dir,exist_ok=True)\n",
    "        os.makedirs('%s/confusion/'%out_dir,exist_ok=True)\n",
    "        os.makedirs('%s/diagnosis/'%out_dir,exist_ok=True)\n",
    "\n",
    "        block_models = []\n",
    "        block_perfs = []\n",
    "        block_aucs = []\n",
    "        block_conf_mats = []    \n",
    "        \n",
    "        if os.path.exists('%s/%s.joblib'%(out_dir,algo)):\n",
    "            print('Already trained, loading ...')\n",
    "            pretrained = joblib.load('%s/%s.joblib'%(out_dir,algo))\n",
    "        else:\n",
    "            pretrained = None\n",
    "            \n",
    "        for f in range(n_splits):\n",
    "            train_data=target_data.query('fold!=@f').copy()\n",
    "\n",
    "            train_pool = train_data[cl_att].unique().tolist()\n",
    "            valid_pool = target_data.query('fold==@f')[cl_att].unique().tolist()\n",
    "\n",
    "            diff = set(valid_pool).difference(train_pool)\n",
    "            print('Removing unobserved %s classes in the training set from the validation fold %d: '%(cl,f),diff)\n",
    "\n",
    "            valid_data=target_data.query('fold==@f & %s in @train_pool'%cl_att)\n",
    "\n",
    "            X_train = train_data[eva_vars]\n",
    "            y_train = train_data[cl_att]\n",
    "            X_test = valid_data[eva_vars]\n",
    "            y_test = valid_data[cl_att] \n",
    "            \n",
    "            if mod==\"biogeo\":\n",
    "                rf_model = BiogeoHabitatModel(model_name=algo, problem=cl, param_dict=params)\n",
    "                if pretrained is not None:\n",
    "                    rf_model.model = pretrained[f]\n",
    "                elif os.path.exists('%s/%s_%d.joblib'%(out_dir,algo,f)):\n",
    "                    rf_model.model = joblib.load('%s/%s_%d.joblib'%(out_dir,algo,f))                   \n",
    "                else:\n",
    "                    rf_model.fit(X_train,y_train)            \n",
    "            elif mod==\"rf\":\n",
    "                rf_model = RandomForestHabitatModel(model_name=algo, problem=cl, param_dict=params)\n",
    "                if pretrained is not None:\n",
    "                    rf_model.prefit(X_train,y_train)\n",
    "                    rf_model.model = pretrained[f]\n",
    "                elif os.path.exists('%s/%s_%d.joblib'%(out_dir,algo,f)):\n",
    "                    rf_model.prefit(X_train,y_train)\n",
    "                    rf_model.model = joblib.load('%s/%s_%d.joblib'%(out_dir,algo,f))                   \n",
    "                else:\n",
    "                    rf_model.fit(X_train,y_train)\n",
    "            elif mod==\"xgb\":\n",
    "                rf_model = XGBoostHabitatModel(model_name=algo, problem=cl, param_dict=params)\n",
    "                if pretrained is not None:\n",
    "                    rf_model.prefit(X_train,y_train)\n",
    "                    rf_model.model = pretrained[f]\n",
    "                elif os.path.exists('%s/%s_%d.joblib'%(out_dir,algo,f)):\n",
    "                    rf_model.prefit(X_train,y_train)\n",
    "                    rf_model.model = joblib.load('%s/%s_%d.joblib'%(out_dir,algo,f)) \n",
    "                else:                \n",
    "                    rf_model.fit(X_train,y_train, X_val=X_test, y_val=y_test)\n",
    "                    fig = rf_model.plot_learning()\n",
    "                    fig.savefig('%s/diagnosis/learning_curve_%d.png'%(out_dir,f))\n",
    "                  \n",
    "            elif mod=='lgbm':\n",
    "                rf_model = LightGBMHabitatModel(model_name=algo, problem=cl, param_dict=params)\n",
    "                if pretrained is not None:\n",
    "                    rf_model.prefit(X_train,y_train)\n",
    "                    rf_model.model = pretrained[f]\n",
    "                elif os.path.exists('%s/%s_%d.joblib'%(out_dir,algo,f)):\n",
    "                    rf_model.prefit(X_train,y_train)\n",
    "                    rf_model.model = joblib.load('%s/%s_%d.joblib'%(out_dir,algo,f)) \n",
    "                else:                \n",
    "                    rf_model.fit(X_train,y_train, X_val=X_test, y_val=y_test)\n",
    "                    fig = rf_model.plot_learning()\n",
    "                    fig.savefig('%s/diagnosis/learning_curve_%d.png'%(out_dir,f)) \n",
    "                \n",
    "            elif mod=='catboost':\n",
    "                rf_model = CatBoostHabitatModel(model_name=algo, problem=cl, param_dict=params)\n",
    "                if pretrained is not None:\n",
    "                    rf_model.prefit(X_train,y_train)\n",
    "                    rf_model.model = pretrained[f]\n",
    "                elif os.path.exists('%s/%s_%d.joblib'%(out_dir,algo,f)):\n",
    "                    rf_model.prefit(X_train,y_train)\n",
    "                    rf_model.model = joblib.load('%s/%s_%d.joblib'%(out_dir,algo,f))\n",
    "                else:                \n",
    "                    rf_model.fit(X_train,y_train, X_val=X_test, y_val=y_test)\n",
    "                    fig = rf_model.plot_learning()\n",
    "                    fig.savefig('%s/diagnosis/learning_curve_%d.png'%(out_dir,f))                 \n",
    "\n",
    "            elif mod==\"mlp\":\n",
    "                rf_model = NeuralHabitatModel(model_name=algo, problem=cl, param_dict=params,device=device)\n",
    "                if pretrained is not None:\n",
    "                    rf_model.prefit(X_train,y_train)\n",
    "                    rf_model.neural_module = pretrained[f]\n",
    "                elif os.path.exists('%s/%s_%d.joblib'%(out_dir,algo,f)):\n",
    "                    rf_model.prefit(X_train,y_train)\n",
    "                    rf_model.neural_module = joblib.load('%s/%s_%d.joblib'%(out_dir,algo,f))\n",
    "                else:                \n",
    "                    rf_model.fit(X_train,y_train, X_val=X_test, y_val=y_test)\n",
    "\n",
    "                    fig = rf_model.plot_learning()\n",
    "                    fig.savefig('%s/diagnosis/learning_curve_%d.png'%(out_dir,f))\n",
    "\n",
    "                    print('Temperature scaling')\n",
    "                    y_logit = rf_model.predict_logit(X_test)\n",
    "                    mlp_temp_sc = TemperatureScaling(predictions=y_logit,labels=y_test,as_logit=True)\n",
    "                    fig1 = mlp_temp_sc.plot_calibration(title='Pre-calibration')\n",
    "                    fig1.savefig('%s/diagnosis/precalibration_%d.png'%(out_dir,f))\n",
    "\n",
    "                    optim = mlp_temp_sc.optimize_temperature()\n",
    "                    fig2 = mlp_temp_sc.plot_calibration('Post-calibration')\n",
    "                    fig2.savefig('%s/diagnosis/postcalibration_%d.png'%(out_dir,f))\n",
    "\n",
    "                    rf_model.temperature = mlp_temp_sc.temperature  \n",
    "                    \n",
    "            elif mod==\"tabnet\":\n",
    "                rf_model = TabNetHabitatModel(model_name=algo, problem=cl, param_dict=params)\n",
    "                if pretrained is not None:\n",
    "                    rf_model.prefit(X_train,y_train)\n",
    "                    rf_model.model = pretrained[f]\n",
    "                elif os.path.exists('%s/%s_%d.joblib'%(out_dir,algo,f)):\n",
    "                    rf_model.prefit(X_train,y_train)\n",
    "                    rf_model.model = joblib.load('%s/%s_%d.joblib'%(out_dir,algo,f))\n",
    "                else:                \n",
    "                    rf_model.fit(X_train,y_train, X_val=X_test, y_val=y_test)\n",
    "\n",
    "                    fig = rf_model.plot_learning()\n",
    "                    fig.savefig('%s/diagnosis/learning_curve_%d.png'%(out_dir,f))\n",
    "\n",
    "                    print('Temperature scaling')\n",
    "                    y_logit = rf_model.predict_proba(X_test)\n",
    "                    mlp_temp_sc = TemperatureScaling(predictions=y_logit,labels=y_test,as_logit=False)\n",
    "                    fig1 = mlp_temp_sc.plot_calibration(title='Pre-calibration')\n",
    "                    fig1.savefig('%s/diagnosis/precalibration_%d.png'%(out_dir,f))\n",
    "\n",
    "                    optim = mlp_temp_sc.optimize_temperature()\n",
    "                    fig2 = mlp_temp_sc.plot_calibration('Post-calibration')\n",
    "                    fig2.savefig('%s/diagnosis/postcalibration_%d.png'%(out_dir,f))\n",
    "\n",
    "                    rf_model.temperature = mlp_temp_sc.temperature                      \n",
    "            \n",
    "            else:\n",
    "                raise('Unrecognized algorithm')\n",
    "            \n",
    "            if pretrained is None:\n",
    "                rf_perfs, rf_conf_mat = rf_model.evaluate(X_test,y_test)\n",
    "                rf_perfs['fold'] = f\n",
    "                rf_perfs['dataset'] = 'GLOBAL'\n",
    "\n",
    "                rf_conf_mat.to_csv('%s/confusion/conf_mat_%d.csv'%(out_dir,f))\n",
    "                fig = plot_confusion_matrix(rf_conf_mat, title='%s, %s, fold: %d'%(algo,cl,f),gs=10)\n",
    "                fig.savefig('%s/confusion/conf_mat_%d.png'%(out_dir,f))\n",
    "\n",
    "                Y_hat = rf_model.predict_proba(X_test)\n",
    "                fig, au_scores=mcroc_eval(Y_hat,y_test,'%s - %s, fold: %d'%(algo,cl,f)) \n",
    "                fig.savefig('%s/confusion/roc_%d.png'%(out_dir,f))\n",
    "                au_scores.update({'fold':f, 'dataset': 'GLOBAL', 'algo': algo})\n",
    "                \n",
    "                block_perfs.append(rf_perfs)\n",
    "                block_aucs.append(au_scores)\n",
    "                block_conf_mats.append(rf_conf_mat)\n",
    "            \n",
    "            joblib.dump(rf_model.model if mod!=\"mlp\" else rf_model.neural_module, '%s/%s_%d.joblib'%(out_dir,algo,f),compress=3)\n",
    "            block_models.append(rf_model)\n",
    "            \n",
    "        if pretrained is None:\n",
    "            if mod=='mlp':\n",
    "                joblib.dump([block.neural_module for block in ensemble_model.models],'%s/%s.joblib'%(out_dir,algo),compress=3)\n",
    "            else:\n",
    "                joblib.dump([block.model for block in ensemble_model.models],'%s/%s.joblib'%(out_dir,algo),compress=3)\n",
    "                        \n",
    "        print('Ensemble model')\n",
    "        ensemble_model = EnsembleHabitatModel(model_names=['%s%d'%(algo,f) for f in range(n_splits)], \n",
    "                                              models=block_models, k_list=[3,5,10], \n",
    "                                              ensemble_name='%s_ensemble'%algo, problem=cl)\n",
    "        \n",
    "        return ensemble_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400c3efd-e173-4fe2-b73c-3d5cdb97bd08",
   "metadata": {},
   "source": [
    "#### Ensemble forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10169c34-541e-4d9c-ab38-a96165300197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_forecasting(ensemble_model,pred_vars,proj_datasets,out_dir):\n",
    "    for dname, dataset in proj_datasets:\n",
    "        print(dname)\n",
    "        Y_raw, Y_score, Y_committee = ensemble_model.predict_proba(dataset[pred_vars])\n",
    "        Y_raw.to_parquet('%s/%s_raw.parquet'%(out_dir,dname),compression='gzip')\n",
    "        Y_score.to_parquet('%s/%s_soft_prediction.parquet'%(out_dir,dname),compression='gzip')\n",
    "        Y_committee.to_parquet('%s/%s_hard_prediction.parquet'%(out_dir,dname),compression='gzip')\n",
    "        \n",
    "        del Y_raw, Y_score, Y_committee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca899a3-6afa-49a7-b96a-038d81414aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a4b17bb-b466-4308-9ea7-7c579491afed",
   "metadata": {},
   "source": [
    "#### Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a96e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb554466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(geo_df,out_folder,dset,algo,palette=None,xlim=None,ylim=None):\n",
    "\n",
    "    pred = pd.read_csv('%s/%s_soft_prediction.csv'%(out_folder,dset),index_col=0)\n",
    "    hardpred = pd.read_csv('%s/%s_hard_prediction.csv'%(out_folder,dset),index_col=0)\n",
    "        \n",
    "    pred[['Longitude','Latitude']]=geo_df\n",
    "    pred['EUNIS']=pred[labels].idxmax(axis=1)\n",
    "    pred['confidence']=pred[labels].max(axis=1)\n",
    "    pred['consensus']=hardpred[labels].max(axis=1)\n",
    "    \n",
    "    if xlim is None:\n",
    "        xmin, xmax = pred['Longitude'].min(), pred['Longitude'].max()\n",
    "        xlim = [xmin, xmax]\n",
    "    \n",
    "    if ylim is None:\n",
    "        ymin, ymax = pred['Latitude'].min(), pred['Latitude'].max()\n",
    "        ylim = [ymin, ymax]\n",
    "    \n",
    "    plot_occurrence(pred, lon_var='Longitude', lat_var='Latitude',att='EUNIS',xlim=xlim,ylim=ylim,title='%s predicted %s habitats'%(algo,cl),msize=2,bgd='black', categorical=True, palette=palette)\n",
    "    plot_occurrence(pred, lon_var='Longitude', lat_var='Latitude',att='confidence',xlim=xlim,ylim=ylim,title='%s predicted %s habitats - confidence'%(algo,cl),msize=2,bgd='black', categorical=False, cmap='viridis')\n",
    "    plot_occurrence(pred, lon_var='Longitude', lat_var='Latitude',att='confidence',xlim=xlim,ylim=ylim,title='%s predicted %s habitats - consensus'%(algo,cl),msize=2,bgd='black', categorical=False, cmap='viridis')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee74c6-8d8a-464a-ac58-dc20d841aef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "600fe19a-3fab-4bfd-bd78-fd534f315fab",
   "metadata": {},
   "source": [
    "## Model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb747d-3c48-461b-b5b2-18f7b5b39ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configurations = \n",
    "{\n",
    "    'MA2':[('rf','wrf'),('xgb','wxgb'),('mlp','mlp3_wldam')],\n",
    "    'N':[('rf','wrf'),('xgb','wxgb'),('mlp','mlp3_wldam')],\n",
    "    'P':[('rf','wrf'),('xgb','wxgb'),('mlp','mlp3_wldam')],\n",
    "    'Q':[('rf','wrf'),('xgb','wxgb'),('mlp','mlpw_wldam') ,('mlp','mlp3_wldam')],\n",
    "    'R':[('rf','rf'),('xgb','xgb'),('mlp','mlpw_ldam')],\n",
    "    'S':[('rf','wrf'),('xgb','xgb'),('lgbm','lgbm'),('mlp','mlpw_ldam')],\n",
    "    'T':[('rf','wrf'),('xgb','xgb'),('lgbm','lgbm'),('mlp','mlp3_fl5')],\n",
    "    'U':[('rf','rf'),('xgb','xgb'),('lgbm','lgbm'),('mlp','mlp3_ldam')]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4374c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75adc325-004e-4cca-99a9-b350b4eaea1c",
   "metadata": {},
   "source": [
    "## Modeling pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2d09e-9cb4-4ce7-902f-3ae2906d798c",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    " <img src=\"training.png\" alt=\"Ensemble model training\" width=\"600\" height=\"600\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1490449-55ec-49d0-b959-124fcd8e162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('habitat_models/full_final/',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae0482-4e1b-4472-92fc-af72ebd31cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = 'MA2'  ## Change this to run another habitat formation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dd7cf8-816a-4b27-b1b9-8ab94aa6f3a6",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c261201b-ac36-4458-8008-7127065ff0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tuples = model_configs.get(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8355f7-317b-490d-8d11-8d608ef4d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = 'habitat_models/'%cl\n",
    "cl_att = 'EUNIS3' if cl!=\"P\" else \"EUNIS2\"\n",
    "eval_datasets = [('EVA':calib_dataset[pred_vars]), ##reprojecting on training dataset\n",
    "                 ('NLPT':nlpt_dataset[pred_vars]), ###projecting on evaluation datasets\n",
    "                 ('AU',au_dataset[pred_vars]), ###projecting on evaluation datasets\n",
    "                 ('IFN',ifn_dataset[pred_vars]), ###projecting on evaluation datasets\n",
    "                 ('PT',pt_dataset[pred_vars]), ###projecting on evaluation datasets7\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e69908-e470-4ef1-9b4e-80fb3f5a015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_dataset = calib_dataset.query('EUNIS1==@cl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486113e-7d7a-4d95-a082-2333d6f04b75",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efae6da-7ac2-4fc3-9e8b-e9d77bdc0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = train_cl_ensemble(cl,cl_dataset,pred_vars,model_tuples,out_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbc8dcd-a990-4be9-8574-6f5aba26cff4",
   "metadata": {},
   "source": [
    "### Forecast on evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a9edd-501d-4e67-a441-fb081de718bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_forecasting(ensemble_model,pred_vars,eval_datasets,out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75214f04-dd73-4b19-8056-c000af52026a",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61486d8f-c203-48c8-b640-baf75084de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dname, dataset in eval_datasets:\n",
    "    geo_df = dataset[['Longitude','Latitude']]\n",
    "    plot_prediction(geo_df,out_folder,dataset)\n",
    "    Y_score = pd.read_parquet('%s/%s_soft_prediction.parquet'%(out_folder,dname)) ### ensemble mean\n",
    "    soft_perfs, soft_conf_mat = eval_classifier(y_score=Y_score,y_true=dataset[cl_att], k_list=[3,5,10],model_name='soft_ensemble', super_class=cl)\n",
    "\n",
    "    soft_perfs.to_csv('%s/%s_perfs.csv'%(out_folder,dname))\n",
    "    soft_conf_mat.to_csv('%s/%s_confusion.csv'%(out_folder,dname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9013062c-f06e-4a7f-968c-4c81211f627f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1829fab-6ca6-4bc7-bb23-ae1ec559d52f",
   "metadata": {},
   "source": [
    "## EUNIS projection at EU scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b825df2-06d7-4f9f-84e9-f03d66489b77",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    " <img src=\"prediction.png\" alt=\"Ensemble projection\" width=\"600\" height=\"600\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f217d0e-013d-4662-bf87-5e0a4ca969f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask_ml.wrappers import ParallelPostFit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da7c57-b345-4ad3-9c73-e0fe1d1efdf5",
   "metadata": {},
   "source": [
    "### Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6aab2-4e9c-43d7-a79a-42c865377de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_vars = ['bio01','bio04','gdd5','bio12','bio15','scd','swe']\n",
    "hydro_vars = ['distace2FW','distance2Coast','inundation_seasonality']\n",
    "topo_vars = ['TPILF','TRI','aspect']\n",
    "geol_vars = ['dr','parmado']\n",
    "soil_phys_vars = ['AWC','BulkDensity','CoarseFragments','SandE','SiltE','ClayE']\n",
    "soil_chem_vars = ['pH_H2O','C','N','CEC','CaCO3']\n",
    "veg_vars = ['canopy_height','lai_spring','lai_summer','canopy_density','SOSD','LSLOPE','AMPL','RSLOPE','LENGTH','TPROD']\n",
    "landscape_vars = ['Grassland','Tree_cover','Built_up','Bare_sparse_vegetation','Cropland','Permanent_water_bodies','Herbaceous_wetland','Shrubland','Moss_lichen','Snow_ice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7c6aa9-af70-4f74-8ad6-292792b6a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "partition_size = 1500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d5eebc-a537-4baf-aca9-3b320ccbdb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = 'habitat_models/full_final/'\n",
    "proj_folder = 'habitat_projection/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd39a988-cc4f-47ab-be70-6825e6b7eadd",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce490dc-1c90-47fb-bca9-3e9e3753cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_partition(start,end):\n",
    "    eu_clim = pd.read_hdf('data/EU100/climate.h5','/data',start=start,stop=end,columns=clim_vars)\n",
    "    eu_hydro = pd.read_hdf('data/EU100/hydro.h5','/data',start=start,stop=end,columns=hydro_vars)\n",
    "    eu_topo = pd.read_hdf('data/EU100/topo.h5','/data',start=start,stop=end,columns=topo_vars)\n",
    "    eu_geol = pd.read_hdf('data/EU100/geology.h5','/data',start=start,stop=end,columns=geol_vars)\n",
    "    eu_phys_soil = pd.read_hdf('data/EU100/physical_soil.h5',start=start,stop=end,columns=soil_phys_vars)\n",
    "    eu_chem_soil = pd.read_hdf('data/EU100/chemical_soil.h5',start=start,stop=end,columns=soil_chem_vars)\n",
    "    eu_veg = pd.read_hdf('data/EU100/vegetation.h5',start=start,stop=end,columns=veg_vars)\n",
    "    eu_landscape = pd.read_hdf('data/EU100/woco.h5',start=start,stop=end,columns=landscape_vars)\n",
    "    \n",
    "    eu_map = pd.concat([eu_clim,eu_hydro,eu_topo,eu_geol,eu_phys_soil,eu_chem_soil,eu_veg,eu_landscape],axis=1)\n",
    "    \n",
    "    return eu_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a7050-4af8-48e7-b3b7-b619bf1f76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_full_ensemble(cl,model_tuples,out_folder,n_splits=5):\n",
    "\n",
    "    block_models = []\n",
    "    for algo, model_name in model_tuples:\n",
    "        params = load_config(algo,'config/%s_config/%s.json'%(cl,model_name))\n",
    "        out_dir = '%s/%s/%s/'%(out_folder,cl,algo)\n",
    "        for fold in range(n_splits):\n",
    "            if algo==\"xgb\":\n",
    "                habitat_model = XGBoostHabitatModel(model_name='%s_%d'%(model_name,fold), problem=cl, param_dict=params)\n",
    "                habitat_model.model = joblib.load('%s/%s_%d.joblib'%(out_dir,model_name,f)) \n",
    "            \n",
    "            if algo==\"rf\":\n",
    "                habitat_model = RandomForestHabitatModel(model_name='%s_%d'%(model_name,fold), problem=cl, param_dict=params)\n",
    "                habitat_model.model = joblib.load('%s/%s_%d.joblib'%(out_dir,model_name,f))        \n",
    "    \n",
    "            if algo==\"lgbm\":\n",
    "                habitat_model = LightGBMHabitatModel(model_name='%s_%d'%(model_name,fold), problem=cl, param_dict=params)\n",
    "                habitat_model.model = joblib.load('%s/%s_%d.joblib'%(out_dir,model_name,f))\n",
    "    \n",
    "            if algo==\"mlp\":\n",
    "                habitat_model = NeuralHabitatModel(model_name='%s_%d'%(model_name,fold), problem=cl, param_dict=params)\n",
    "                habitat_model.model = joblib.load('%s/%s_%d.joblib'%(out_dir,model_name,f))\n",
    "\n",
    "            if algo==\"tabnet\":\n",
    "                habitat_model = TabNetHabitatModel(model_name='%s_%d'%(model_name,fold), problem=cl, param_dict=params)\n",
    "                habitat_model.model = joblib.load('%s/%s_%d.joblib'%(out_dir,model_name,f))            \n",
    "                \n",
    "            block_models.append(habitat_model)\n",
    "            names_models.append('%s_%d'%(model_name,fold))\n",
    "\n",
    "    ensemble_model = EnsembleHabitatModel(model_names=names_models, models=block_models, k_list=[3,5,10], ensemble_name='%s_ensemble'%algo, problem=cl)\n",
    "\n",
    "    return ensemble_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609742d1-db80-497c-a293-1616869e7eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_partition(partition,cl,model_tuples,model_folder,proj_folder):\n",
    "    start = partition*size\n",
    "    end = start+size\n",
    "    eu_map = load_partition(start,end)\n",
    "\n",
    "    ensemble_model = generate_ensemble(cl,model_tuples,out_folder,n_splits=5)\n",
    "    _, Y_score, Y_committee = ensemble_model.predict_proba(eu_map)\n",
    "\n",
    "    Y_score.to_parquet('%s/%s_soft_prediction_%d.parquet'%(proj_folder,cl,partition))  ### soft ensemble averaging (mean)\n",
    "    Y_committee.to_parquet('%s/%s_hard_prediction_%d.parquet'%(proj_folder,cl,partition)) ### hard ensemble averaging (committee vote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90472236-f1c3-48e9-a5dd-69fe332e258b",
   "metadata": {},
   "source": [
    "### Run projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784b8bf6-699a-4f98-9518-87c784b7c6fe",
   "metadata": {},
   "source": [
    "We run parallel predictions across partitions and habitat formations on a computing grid. Here's an example to run for one particular run: partition, habitat formation (cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be536504-df71-41d3-adc8-0c1439e97065",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = 0\n",
    "cl = 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bbea1b-07ad-4d21-b8ba-4b1b21e14759",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tuples = model_configs.get(cl)\n",
    "project_partition(partition,cl,model_tuples,model_folder,f\"{proj_folder}/{cl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8fe61a-c288-4cf9-8d27-54376cf50081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69b0781a-910b-480e-b1cf-3df3a7882dd9",
   "metadata": {},
   "source": [
    "### Merge partition results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1203c-8036-4138-8ed4-6baa53935065",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5eb49e-17aa-4842-9cbb-72ca247b55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = f\"{proj_folder}/{cl}/soft_prediction_*.parquet\"\n",
    "matching_files = glob.glob(pattern)\n",
    "\n",
    "full_soft_projection = pd.concat([pd.read_parquet(file) for file in matching_files],axis=0,ignore_index=True)\n",
    "full_soft_projection.to_parquet(f\"{proj_folder}/{cl}_soft_prediction.parquet\")\n",
    "\n",
    "full_hard_projection = pd.concat([pd.read_parquet(file) for file in matching_files],axis=0,ignore_index=True)\n",
    "full_hard_projection.to_parquet(f\"{proj_folder}/{cl}_hard_prediction.parquet\")\n",
    "\n",
    "shutil.rmtree(f\"{proj_folder}/{cl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf06a35-1b92-4c98-954d-af47e1c78460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35ed1671-ca19-4a9f-b8a3-65a5d85f474d",
   "metadata": {},
   "source": [
    "## EUNIS wall-to-wall mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca2934-cc3d-4be1-896d-d1f0ed26955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapping_utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939cee93-30d7-425d-8ee0-e7a1bd9c03ff",
   "metadata": {},
   "source": [
    "Ensemble model projections provide for each habitat formation (e.g. Grasslands (R)) across the project extent (EEA39) the probabilities of all habitat classes within the formation such that the probabilities sum to 1. In the following, we use these projections to generate habitat maps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93401304-d526-4153-8b8f-509410c0d2fb",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    " <img src=\"mapping_workflow.png\" alt=\"Mapping Worflow\" width=\"600\" height=\"600\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd76826b-7bcf-4202-8337-6be9ae975bca",
   "metadata": {},
   "source": [
    "## General preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7c8a5-d016-42e5-9038-c095bcb23d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_folder = 'habitat_projection/'\n",
    "map_folder = 'habitat_maps/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b58be-fea3-4bfc-880e-d53104e2ef9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc40bda2-2ab0-45c6-aa1e-a59cd3661981",
   "metadata": {},
   "source": [
    "### Habitat classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fbe6c9-7bd9-498b-b67a-de6d57defbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "formations = ['MA2','N','P','Q','R','S','T','U']\n",
    "\n",
    "with open('config/habitat_classes.json','r') as fp:\n",
    "    habitat_classes = json.load(fp)\n",
    "\n",
    "formations = list(habitat_classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c583899-4068-4c4e-9548-fe773443a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_legend = pd.read_csv('config/habitat_legend.csv')\n",
    "name2code = map_legend[['Code_name','Code']].set_index('Code_name')['Code'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b4ceb-3474-4618-9e99-fefdc1d3a0a7",
   "metadata": {},
   "source": [
    "### Map mask settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d411e0-bc29-4906-ac2b-3455f6cc3dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### These are the valid pixels where projection was done\n",
    "map_metadata=pd.read_parquet('data/EU100/metadata.parquet') ## coordinates in EPSG:3035\n",
    "xmin, ymin = map_metadata[['X','Y']].min()\n",
    "xmax, ymax = map_metadata[['X','Y']].max()\n",
    "\n",
    "w = (xmax - xmin) // res \n",
    "h = (ymax - ymin) // res\n",
    "\n",
    "print('Indexing')\n",
    "profile = get_rasterio_profile(count=1,height=h,width=w,bounds=(xmin, ymin, xmax, ymax),epsg=3035,blockxsize=256,blockysize=256,dtype=np.uint8,params={'BIGTIFF':'YES'})\n",
    "out_fn = 'temporary.tif'\n",
    "out_raster = rio.open(out_fn, 'w+', **profile)\n",
    "\n",
    "indices = out_raster.index(x=map_metadata['X'].values,y=map_metadata['Y'].values)\n",
    "rows = np.minimum(indices[0],int(h-1))\n",
    "cols = np.minimum(indices[1],int(w-1))\n",
    "\n",
    "map_metadata['row_idx']=rows\n",
    "map_metadata['col_idx']=cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c9b53-068f-47bd-96a4-151c7f238db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00cd9720-bc66-40df-910e-9294674d695a",
   "metadata": {},
   "source": [
    "### Generate regional (coastline, endemism to ecoregions) mask layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60dee2c-9d36-409d-bfb3-1ea48c83a5ad",
   "metadata": {},
   "source": [
    "Habitat definitions are sometimes by definition associated to a specific ecoregion (inland habitats) or coastlines (coastal habitats). For instance, Baltic coastal meadows are by definition in the Baltic coast, whereas Pannonian sandy steppes are by definition in the Pannonian ecoregion. \n",
    "\n",
    "To account for this, we generate spatial masks following coastline layers and ecoregion layers for each habitat class. In the absence of any spatially explicit information in the definition of a given habitat class, we generate an all-ones mask (meaning we're not making any region)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15289b39-e096-4b2c-bdd7-96a734979d7b",
   "metadata": {},
   "source": [
    "Raster masks (coastline, ecoregions) have been aligned to the mapping mask (corine land cover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe91dd1-dbb6-43e6-9814-dc0bf357ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "coastal_areas = rio.open('data/EU100/coastline.tif').read(1)\n",
    "\n",
    "ecoregions_db = gpd.read_file('data/Ecoregions2017/Ecoregions2017.shp')\n",
    "ecoregions_db = ecoregions_db.query('ECO_NAME in @ecoreg_list').to_crs(3035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b681d6-d2bf-49f7-a6b4-837e43e435f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_metadata['coastline'] = coastline[rows,cols]\n",
    "map_metadata['ecoregion'] = ecoregions[rows,cols]\n",
    "map_metadata['corine'] = corine[rows,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe3035-bc59-4363-84ee-57298a49a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('crosswalks/coastline_codes.json','r') as fp:\n",
    "    coastline_nomen = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8922c7-62d4-45b4-9932-954ec2f30df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('%s/masks'%map_folder,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2518e749-1157-4295-bcbd-48f6785526f1",
   "metadata": {},
   "source": [
    "#### Coastal habitats (MA2, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83232ee-71db-493b-852d-4c8dc7040dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in ['MA2','N']:\n",
    "    coastline_mask = pd.read_csv('crosswalks/%s_coastline.csv'%cl,index_col=0)\n",
    "    labels = coastline_mask.columns.tolist()\n",
    "    \n",
    "    all_masks = []\n",
    "    for cl3 in labels:\n",
    "        print('Generating mask for %s'%cl3)\n",
    "        arr_mask = np.zeros_like(coastal_areas)\n",
    "        sel_codes = [coastline_map.get(x) for x in coastline_mask.query('%s>0'%cl3).index.tolist()]\n",
    "        for c in sel_codes:\n",
    "            arr_mask[coastal_areas==c]=1\n",
    "    \n",
    "        all_masks.append(arr_mask)\n",
    "    \n",
    "    mask_stack = np.stack(all_masks,axis=2)\n",
    "    mask_stack[coastal_areas==255]=255\n",
    "    out_arr = np.transpose(mask_stack,[2,0,1])\n",
    "    \n",
    "    out_fn = f'{map_folder}/masks/regional_mask_{cl}.tif'\n",
    "\n",
    "    ###### Prepare raster\n",
    "    profile = get_rasterio_profile(count=len(labels),height=h,width=w,bounds=(xmin, ymin, xmax, ymax),epsg=3035,blockxsize=256,blockysize=256,\n",
    "                                   dtype=np.uint8,params={'BIGTIFF':'YES'})\n",
    "    \n",
    "    write_geotiff_tags(out_arr, profile, out_fn, nodata=255, tags={'Author': 'Sara Simoussi', 'Organism': 'LECA-CNRS', 'Project':'EO4diversity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb5bd9-68e5-477c-887b-0581b22e1448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e64be738-f277-4939-8820-6ea299a2d80e",
   "metadata": {},
   "source": [
    "#### Inland habitats (Q, R, S, T, U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51abcc6a-a956-442b-afdb-614d72265c93",
   "metadata": {},
   "source": [
    "For inland habitats, except freshwater and man-made vegetation, we use ecoregions to generate regional masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07fa31-a5c8-49fc-ac20-1bb517e43137",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "habitat2ecoregion = pd.read_csv('crosswalks/ecoregion_habitat_mask.csv').set_index(['EUNIS1','EUNIS2','EUNIS3'])\n",
    "ecoreg_list = habitat2ecoregion.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f0ae6-0036-47a7-9ab6-17f85d81c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('masks/ecoregions_binary',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4edd93-7428-4532-80ee-ba2477ba27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in formations[2:]:\n",
    "    cl3_labels = habitat_classes.get(cl)\n",
    "    l_masks = []\n",
    "    for cl3 in cl3_labels:\n",
    "        print(cl3)\n",
    "        out_file = 'masks/ecoregions_binary/%s.tif'%eunis_cl3\n",
    "        l_regions = habitat2ecoregion.loc[eunis_cl1].loc[eunis_cl2].loc[[eunis_cl3]].T.query('%s>0'%eunis_cl3).index.tolist()\n",
    "        reg_df = ecoregions_db.query('ECO_NAME in @l_regions')\n",
    "        rasterize_shapefile(vect_obj=reg_df,out_file=out_file,mask_file='data/EU100/clc2018.tif')\n",
    "\n",
    "        arr = rio.open(out_file).read(1)\n",
    "        l_masks.append(arr)\n",
    "\n",
    "    ecoreg_stack = np.stack(l_masks,axis=0)\n",
    "    \n",
    "    ###### Save mask raster\n",
    "    out_fn = f'{map_folder}/masks/regional_mask_{cl}.tif'\n",
    "    profile = get_rasterio_profile(count=len(labels),height=h,width=w,bounds=(xmin, ymin, xmax, ymax),epsg=3035,blockxsize=256,blockysize=256,\n",
    "                                   dtype=np.uint8,params={'BIGTIFF':'YES'})\n",
    "    \n",
    "    write_geotiff_tags(ecoreg_stack, profile, out_fn, nodata=255, tags={'Author': 'Sara Simoussi', 'Organism': 'LECA-CNRS', 'Project':'EO4diversity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c368b-41f3-405a-ab04-647a3abf6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('masks/ecoregions_binary/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58272c02-7acc-49c1-afe9-2c09cbb55da4",
   "metadata": {},
   "source": [
    "### Generate land cover masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427302d0-d521-42f1-864a-0c36607e7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "corine_landcover = rio.open('data/EU100/clc2018.tif').read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11462f75-c140-47b7-86ea-470972850aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corine_mask = pd.read_csv('crosswalks/corine_mask.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd4834-8373-4637-9387-75b87fd18b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in formations:\n",
    "    cl3_labels = habitat_classes.get(cl)\n",
    "    cl3_mask = corine_mask[cl3_labels]\n",
    "    \n",
    "    all_masks = []\n",
    "    for cl3 in labels:\n",
    "        print('Generating mask for %s'%cl3)\n",
    "        arr_mask = np.zeros_like(corine_landcover)\n",
    "        sel_codes = [x for x in corine_mask.query('%s>0'%cl3).index.tolist()]\n",
    "        for c in sel_codes:\n",
    "            arr_mask[corine_landcover==c]=1\n",
    "    \n",
    "        all_masks.append(arr_mask)\n",
    "    \n",
    "    mask_stack = np.stack(all_masks,axis=2)\n",
    "    mask_stack[corine_landcover==255]=255\n",
    "    out_arr = np.transpose(mask_stack,[2,0,1])\n",
    "    \n",
    "    out_fn = f'{map_folder}/masks/landcover_mask_{cl}.tif'\n",
    "\n",
    "    ###### Prepare raster\n",
    "    profile = get_rasterio_profile(count=len(labels),height=h,width=w,bounds=(xmin, ymin, xmax, ymax),epsg=3035,blockxsize=256,blockysize=256,\n",
    "                                   dtype=np.uint8,params={'BIGTIFF':'YES'})\n",
    "    \n",
    "    write_geotiff_tags(out_arr, profile, out_fn, nodata=255, tags={'Author': 'Sara Simoussi', 'Organism': 'LECA-CNRS', 'Project':'EO4diversity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5607603-96a1-4327-8630-b7179016a267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "144a81cc-b698-4fe1-9e6d-fd699fdbb9fa",
   "metadata": {},
   "source": [
    "## STEP 1: Habitat suitability maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9bf03-43f7-4360-9710-37eafdb20406",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('habitat_maps/suitability/',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325ab003-8090-4760-adf4-18257bcdf373",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in formations:\n",
    "    #### Read ensemble projections\n",
    "    cl_data = pd.read_parquet(f\"{proj_folder}/{cl}_soft_prediction.parquet\")\n",
    "\n",
    "    #### Output file\n",
    "    out_fn = 'habitat_maps/suitability/%s.tif'%cl\n",
    "    \n",
    "    ###### Prepare raster\n",
    "    profile = get_rasterio_profile(count=len(cl3_labels),height=h,width=w,bounds=(xmin, ymin, xmax, ymax),epsg=3035,blockxsize=256,blockysize=256,\n",
    "                                   dtype=np.uint8,params={'BIGTIFF':'YES'})\n",
    "    \n",
    "    out_raster = rio.open(out_fn, 'w+', **profile)\n",
    "    out_arr = out_raster.read()\n",
    "    out_arr[:]=255\n",
    "\n",
    "    for i, cl3 in enumerate(cl3_labels):\n",
    "        print(cl3)\n",
    "        out_arr[i][row_coast,col_coast] = cl_data.loc[idx_coast,cl3].values//100\n",
    "\n",
    "    min_vals = cl_data.loc[idx_coast,cl3_labels].min()\n",
    "    max_vals = cl_data.loc[idx_coast,cl3_labels].max()\n",
    "    min_vals = min_vals//100\n",
    "    max_vals = max_vals//100\n",
    "\n",
    "    suit_scales = list(1/max_vals.values)\n",
    "\n",
    "    write_geotiff_tags(out_arr,\n",
    "                       profile,\n",
    "                       out_fn,\n",
    "                       nodata=255,\n",
    "                       tags={'Author': 'Sara Simoussi', 'Organism': 'LECA-CNRS-UGA'},\n",
    "                       scales=suit_scales,\n",
    "                       offsets=[0]*len(cl3_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c364dc0b-0b5e-42a2-a773-5bc802c96ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b4ae353-781a-42c6-95a4-96e26eecd02c",
   "metadata": {},
   "source": [
    "## STEP 2: Habitat probability maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ecd31-2e69-43c7-bda4-6b3253fb7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('habitat_maps/probability/',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ece9b-f50e-42e4-ab43-810dc0872f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in formations:\n",
    "    cl3_labels = habitat_classes.get(cl)\n",
    "    out_fn = 'habitat_maps/probability/%s.tif'%cl\n",
    "    \n",
    "    suit_arr = rio.open('habitat_maps/suitability/%s_suitability.tif'%cl).read()\n",
    "    mask_arr = rio.open('masks/regional_mask_%s.tif'%cl).read()\n",
    "\n",
    "    oom_mask = (suit_arr==255)\n",
    "    suit_arr[oom_mask] = 0\n",
    "\n",
    "    filt_arr = suit_arr * mask_arr\n",
    "    max_vals = filt_arr.max(axis=(1,2))\n",
    "    suit_scales = list(1/np.maximum(max_vals,1))\n",
    "    filt_arr[oom_mask] = 255\n",
    "\n",
    "    profile = get_rasterio_profile(count=len(cl3_labels),height=h,width=w,bounds=(xmin, ymin, xmax, ymax),epsg=3035,blockxsize=256,blockysize=256,\n",
    "                                   dtype=np.uint8,params={'BIGTIFF':'YES'})\n",
    "\n",
    "    write_geotiff_tags(filt_arr,\n",
    "                   profile,\n",
    "                   out_fn,\n",
    "                   nodata=255,\n",
    "                   tags={'Author': 'Sara Simoussi', 'Organism': 'LECA-CNRS-UGA'},\n",
    "                   #bands_tags=[{'band1':cl3}],\n",
    "                   scales=suit_scales,\n",
    "                   offsets=[0]*len(cl3_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dcfc66-52cf-4f92-8cab-a073461e5a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b774c4fc-e8d1-43e6-bee1-1e97285a163e",
   "metadata": {},
   "source": [
    "## STEP 3: Formation habitat maps (with land use filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef522d11-201b-4b82-a3c8-32b4ec5c704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('habitat_maps/topK/',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ebedd7-89a3-4eb0-9933-d32c464544b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_map_code = np.vectorize(lambda c: name2code(cl3_labels[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706043a9-732c-4f87-8a85-bd869c68c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in formations:\n",
    "    cl3_labels = habitat_classes.get(cl)\n",
    "    out_fn = 'habitat_maps/probability/%s.tif'%cl\n",
    "\n",
    "    ### Load probability maps\n",
    "    prob_arr = rio.open('habitat_maps/probability/%s_probability.tif'%cl).read()\n",
    "\n",
    "    ### Mask nodata areas\n",
    "    oom_mask = (prob_arr==255)\n",
    "    prob_arr[oom_mask] = np.nan\n",
    "    \n",
    "    ### Load landcover masks\n",
    "    mask_arr = rio.open('masks/landcover_mask_%s.tif'%cl).read()\n",
    "\n",
    "    ### Apply filter\n",
    "    filt_arr = prob_arr * mask_arr\n",
    "    del prob_arr, mask_arr\n",
    "\n",
    "    ### Rescale probabilities\n",
    "    scale_factor = np.nansum(filt_arr)\n",
    "    scaled_arr = filt_arr / scale_factor\n",
    "    del scaled_arr\n",
    "\n",
    "    ### Top-1 decision\n",
    "    top1_class = scaled_arr.argmax(axis=0,skipna=True)\n",
    "    top1_confidence = scaled_confidence.max(axis=0)    \n",
    "\n",
    "    ### Top-2 decision\n",
    "    is_top1 = (scaled_confidence==top1_confidence.values.reshape(-1,1))\n",
    "    scaled_confidence[is_top1]=np.nan\n",
    "\n",
    "    top2_class = scaled_arr.argmax(axis=0,skipna=True)\n",
    "    top2_confidence = scaled_confidence.max(axis=0)  \n",
    "\n",
    "    ### Top-3 decision\n",
    "    is_top2 = (scaled_confidence==top2_confidence.values.reshape(-1,1))\n",
    "    scaled_confidence[is_top2]=np.nan\n",
    "\n",
    "    top3_class = scaled_arr.argmax(axis=0,skipna=True)\n",
    "    top3_confidence = scaled_confidence.max(axis=0) \n",
    "\n",
    "    ### Combine top-k maps\n",
    "    topk = np.stack([top1_class,top2_class,top3_class],axis=0)\n",
    "    topk_confidence = np.stack([top1_confidence,top2_confidence,top3_confidence],axis=0)\n",
    "\n",
    "    ### Assign map codes\n",
    "    topk_codes = get_map_code(topk)\n",
    "    del topk\n",
    "    \n",
    "    profile = get_rasterio_profile(count=3,height=h,width=w,bounds=(xmin, ymin, xmax, ymax),epsg=3035,blockxsize=256,blockysize=256,\n",
    "                                   dtype=np.uint16,params={'BIGTIFF':'YES'})\n",
    "\n",
    "    out_fn = 'habitat_maps/topK/%s_topk.tif'%cl\n",
    "    write_geotiff_tags(topk_codes.astype(np.uint16),\n",
    "                   profile,\n",
    "                   out_fn,\n",
    "                   nodata=65535,\n",
    "                   tags={'Author': 'Sara Simoussi', 'Organism': 'LECA-CNRS-UGA'},\n",
    "                   scales=[1,1,1],\n",
    "                   offsets=[0,0,0])\n",
    "\n",
    "    profile = get_rasterio_profile(count=3,height=h,width=w,bounds=(xmin, ymin, xmax, ymax),epsg=3035,blockxsize=256,blockysize=256,\n",
    "                                   dtype=np.uint8,params={'BIGTIFF':'YES'})\n",
    "\n",
    "    out_fn = 'habitat_maps/topK/%s_topk_confidence.tif'%cl\n",
    "    write_geotiff_tags((topk_confidence*100).round(0).astype(np.uint8),\n",
    "                   profile,\n",
    "                   out_fn,\n",
    "                   nodata=255,\n",
    "                   tags={'Author': 'Sara Simoussi', 'Organism': 'LECA-CNRS-UGA'},\n",
    "                   scales=[1,1,1],\n",
    "                   offsets=[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdeb6e2-1340-43b6-9ce6-5231df0398d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e864bb8-6e67-4744-ab18-b52442986734",
   "metadata": {},
   "source": [
    "## STEP 4: Wall-to-wall habitat map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c70c9-4b6b-43ae-adc4-e9679748a7b6",
   "metadata": {},
   "source": [
    "### Land cover priority rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaadbe1-5c06-4cd3-9c9a-a51438935ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corine_crosswalk = pd.read_csv('crosswalks/corine_crosswalk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e434b-f891-4076-89de-8765d9aa43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corine_landcover = rio.open('data/EU100/clc2018.tif').read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8241ee-c5fe-4d48-a72c-26bb335ac010",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_map = np.stack([np.empty_like(corine_landcover)]*3,axis=0,dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6be6d6-b534-499d-a1ee-5227f51cb664",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, priority_order in corine_crosswalk[['corine','Priority_order']]:\n",
    "    parsed_order = priority_order.split(',')\n",
    "    top1_formation = parsed_order[0]\n",
    "    top2_formation = parsed_order[1] if len(parsed_order)>1 else ''\n",
    "    top3_formation = parsed_order[2] if len(parsed_order)>2 else ''\n",
    "\n",
    "    sel_mask = (corine_landcover==c)\n",
    "    selection_map[0][sel_mask] = top1_formation\n",
    "    selection_map[1][sel_mask] = top2_formation\n",
    "    selection_map[2][sel_mask] = top3_formation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8a8e1-bac8-4766-9cf9-f105fa1c1636",
   "metadata": {},
   "source": [
    "### Combining topK maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb65c3-daad-45c6-a4a1-f5d67261099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2w_map = np.stack([np.zeros_like(corine_landcover)]*3,axis=0,dtype=np.uint16)\n",
    "w2w_confidence = np.stack([np.zeros_like(corine_landcover)]*3,axis=0,dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33002336-ff53-49a2-aced-938dbe4fcb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in formations:\n",
    "    print('Setting pixels of %s'%cl)\n",
    "    topk_map = rio.open('habitat_maps/topK/%s_topk.tif'%cl).read()\n",
    "    topk_confidence = rio.open('habitat_maps/topK/%s_topk_confidence.tif'%cl).read()\n",
    "\n",
    "    for i in range(3):\n",
    "        sel_mask = (selection_map[i]==cl)\n",
    "        w2w_map[i][sel_mask] = topk_map[0][sel_mask]\n",
    "\n",
    "        sel_mask = (selection_map[i]==cl)\n",
    "        w2w_confidence[i][sel_mask] = topk_confidence[0][sel_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905a19a4-1a89-45f1-a65b-ef6696cf4787",
   "metadata": {},
   "source": [
    "### Manual setting of non-target habitats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df3079-7ce8-479c-8f08-57af80292925",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in ['NODATA','URBAN','SEA_OCEAN','WATER_COURSE','LAKES_RESERVOIRS','TRANSITIONAL_WATER']:\n",
    "    sel_mask = (selection_map[i]==cl)\n",
    "    w2w_map[0][sel_mask] = name2code.get(cl)\n",
    "    w2w_map[0][sel_mask] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd18433-76c1-4943-81d5-92d3056265ab",
   "metadata": {},
   "source": [
    "### Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fed91c-4d49-4c3b-8af6-8d0465863838",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fn = 'habitat_maps/wall2wall/wall2wall.tif'\n",
    "profile = get_rasterio_profile(count=3,height=h,width=w,bounds=(xmin, ymin, xmax, ymax),epsg=3035,blockxsize=256,blockysize=256,\n",
    "                               dtype=np.uint16,params={'BIGTIFF':'YES'})\n",
    "write_geotiff_tags(w2w_map.astype(np.uint16),\n",
    "               profile,\n",
    "               out_fn,\n",
    "               nodata=65535,\n",
    "               tags={'Author': 'Sara Simoussi', 'Organism': 'LECA-CNRS-UGA'},\n",
    "               scales=[1,1,1],\n",
    "               offsets=[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd983a-8cff-4548-ba9a-f3f37a6e0079",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fn = 'habitat_maps/wall2wall/wall2wall_confidence.tif'\n",
    "profile = get_rasterio_profile(count=3,height=h,width=w,bounds=(xmin, ymin, xmax, ymax),epsg=3035,blockxsize=256,blockysize=256,\n",
    "                               dtype=np.uint8,params={'BIGTIFF':'YES'})\n",
    "write_geotiff_tags(w2w_confidence.astype(np.uint8),\n",
    "               profile,\n",
    "               out_fn,\n",
    "               nodata=255,\n",
    "               tags={'Author': 'Sara Simoussi', 'Organism': 'LECA-CNRS-UGA'},\n",
    "               scales=[1,1,1],\n",
    "               offsets=[0,0,0])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "781px",
    "left": "60px",
    "top": "110.525px",
    "width": "365.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
